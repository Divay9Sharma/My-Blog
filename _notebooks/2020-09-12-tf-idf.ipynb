{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Term Frequency(tf) and Inverse Document Frequency(idf) in Information Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:35:40.537903Z",
     "start_time": "2020-09-30T11:35:36.301953Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Divay\n",
      "[nltk_data]     Sharma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "c:\\users\\divay sharma\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "stopWords = set(list(ENGLISH_STOP_WORDS) + nltk.corpus.stopwords.words('english'))\n",
    "regex = RegexpTokenizer('\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:35:44.296323Z",
     "start_time": "2020-09-30T11:35:44.284337Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"1.Boolean model (Doc1) '''The (standard) Boolean model of information retrieval (BIR)[1] is a classical information retrieval (IR) model and, at the same time, the first and most-adopted one. It is used by many IR systems to this day.[citation needed] The BIR is based on Boolean logic and classical set theory in that both the documents to be searched and the user's query are conceived as sets of terms. Retrieval is based on whether or not the documents contain the query terms. '''\\n\",\n",
       " \"2.probabilistic relevance model(doc2) '''The probabilistic relevance model[1][2] was devised by Stephen E. Robertson and Karen SpÃ¤rck Jones as a framework for probabilistic models to come. It is a formalism of information retrieval useful to derive ranking functions used by search engines and web search engines in order to rank matching documents according to their relevance to a given search query.It is a theoretical model estimating the probability that a document dj is relevant to a query q. The model assumes that this probability of relevance depends on the query and document representations. Furthermore, it assumes that there is a portion of all documents that is preferred by the user as the answer set for query q. Such an ideal answer set is called R and should maximize the overall probability of relevance to that user. The prediction is that documents in this set R are relevant to the query, while documents not present in the set are non-relevant. '''\\n\",\n",
       " \"3.Vector space model(doc3) '''Vector space model or term vector model is an algebraic model for representing text documents (and any objects, in general) as vectors of identifiers (such as index terms). It is used in information filtering, information retrieval, indexing and relevancy rankings. Its first use was in the SMART Information Retrieval System. Each dimension corresponds to a separate term. If a term occurs in the document, its value in the vector is non-zero. Several different ways of computing these values, also known as (term) weights, have been developed. One of the best known schemes is tf-idf weighting (see the example below).The definition of term depends on the application. Typically terms are single words, keywords, or longer phrases. If words are chosen to be the terms, the dimensionality of the vector is the number of words in the vocabulary (the number of distinct words occurring in the corpus).Vector operations can be used to compare documents with queries. '''\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"assi3_data.txt\",\"r\").readlines()\n",
    "file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tf-idf weight is a weight often used in information retrieval and text mining. This weight is a statistical measure used to evaluate how important a word is to a document in a collection or corpus. The importance increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus (data-set).\n",
    "\n",
    "#### Term Frequency\n",
    "This measures the frequency of a word in a document. This highly depends on the length of the document and the generality of word. TF is individual to each document and word, hence we can formulate TF as follows.\n",
    "\n",
    "#### Document Frequency\n",
    "This measures the importance of document in whole set of corpus, this is very similar to TF. The only difference is that TF is frequency counter for a term t in document d, where as DF is the count of occurrences of term t in the document set N.\n",
    "\n",
    "#### Inverse Document Frequency\n",
    "IDF is the inverse of the document frequency which measures the informativeness of term t.\n",
    "\n",
    "\\begin{align}\n",
    "tf-idf(t, d) = tf(t, d) * log(N/(df + 1))\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:35:48.789392Z",
     "start_time": "2020-09-30T11:35:48.779417Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_tf_idf(file):\n",
    "    N = len(file)\n",
    "    tf = []\n",
    "    word_count = []\n",
    "    idf = {}\n",
    "    for doc in file:\n",
    "        words = regex.tokenize(doc)\n",
    "        doc_dict = {}\n",
    "        count = 0\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            if word not in stopWords:\n",
    "                if word not in idf:\n",
    "                    idf[word] = 0\n",
    "                count = count + 1\n",
    "                if word not in doc_dict:\n",
    "                    doc_dict[word] = 1\n",
    "                else:\n",
    "                    doc_dict[word] = doc_dict[word] + 1\n",
    "        tf.append(doc_dict)\n",
    "        word_count.append(count)\n",
    "        \n",
    "    #Calculate tf\n",
    "    for i in range(N):\n",
    "        for word in tf[i]:\n",
    "            tf[i][word] = tf[i][word]/word_count[i]\n",
    "    \n",
    "    #Calculate tdf\n",
    "    for word in idf:\n",
    "        for i in range(N):\n",
    "            if word in tf[i]:\n",
    "                idf[word] = idf[word]+1\n",
    "        idf[word] = np.log(N/(idf[word]+1) +1)\n",
    "\n",
    "    #Calculate tf-idf\n",
    "    tf_idf = tf\n",
    "    for i in range(N):\n",
    "        for word in tf_idf[i]:\n",
    "            tf_idf[i][word] = tf[i][word]*idf[word]\n",
    "\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:35:51.212488Z",
     "start_time": "2020-09-30T11:35:51.209418Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_idf = calculate_tf_idf(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf-idf value for 1st document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:36:24.193949Z",
     "start_time": "2020-09-30T11:36:24.187964Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 0.03150669002545206,\n",
       " 'boolean': 0.06247436808232875,\n",
       " 'model': 0.03815562190468791,\n",
       " 'doc1': 0.020824789360776252,\n",
       " 'standard': 0.020824789360776252,\n",
       " 'information': 0.02543708126979194,\n",
       " 'retrieval': 0.03815562190468791,\n",
       " 'bir': 0.041649578721552505,\n",
       " 'classical': 0.041649578721552505,\n",
       " 'ir': 0.041649578721552505,\n",
       " 'time': 0.020824789360776252,\n",
       " 'adopted': 0.020824789360776252,\n",
       " 'used': 0.01271854063489597,\n",
       " 'systems': 0.020824789360776252,\n",
       " 'day': 0.020824789360776252,\n",
       " 'citation': 0.020824789360776252,\n",
       " 'needed': 0.020824789360776252,\n",
       " 'based': 0.041649578721552505,\n",
       " 'logic': 0.020824789360776252,\n",
       " 'set': 0.01575334501272603,\n",
       " 'theory': 0.020824789360776252,\n",
       " 'documents': 0.02543708126979194,\n",
       " 'searched': 0.020824789360776252,\n",
       " 'user': 0.01575334501272603,\n",
       " 'query': 0.03150669002545206,\n",
       " 'conceived': 0.020824789360776252,\n",
       " 'sets': 0.020824789360776252,\n",
       " 'terms': 0.03150669002545206,\n",
       " 'contain': 0.020824789360776252}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T12:58:43.696213Z",
     "start_time": "2020-09-18T12:58:43.681611Z"
    }
   },
   "outputs": [],
   "source": [
    "def chcek_query(tf_idf,query):\n",
    "    N = len(tf_idf)\n",
    "    vocab = []\n",
    "    query = regex.tokenize(query)\n",
    "    for word in query:\n",
    "        word = word.lower()\n",
    "        if word not in stopWords:\n",
    "            vocab.append(word)\n",
    "    doc_score = []\n",
    "    for i in range(N):\n",
    "        score = 0\n",
    "        for word in vocab:\n",
    "            if word in tf_idf[i]:\n",
    "                score = score + tf_idf[i][word]\n",
    "        doc_score.append(score)\n",
    "    print(doc_score)\n",
    "    return doc_score.index(max(doc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T13:03:16.584711Z",
     "start_time": "2020-09-18T13:03:16.579188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03815562190468791, 0.024331121214583595, 0.10631987785261035]\n",
      "Doc 2\n"
     ]
    }
   ],
   "source": [
    "query = \"Vector space model\"\n",
    "print(\"Doc \" + str(chcek_query(tf_idf,query)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T13:03:33.226674Z",
     "start_time": "2020-09-18T13:03:33.218397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0.029879045604592015, 0]\n",
      "Doc 1\n"
     ]
    }
   ],
   "source": [
    "query = \"Stephen E. Robertson\"\n",
    "print(\"Doc \" + str(chcek_query(tf_idf,query)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T13:04:04.083183Z",
     "start_time": "2020-09-18T13:04:04.077268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10524228189603235, 0.012165560607291797, 0.03108976599641237]\n",
      "Doc 0\n"
     ]
    }
   ],
   "source": [
    "query = \"classical information retrieval\"\n",
    "print(\"Doc \" + str(chcek_query(tf_idf,query)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
