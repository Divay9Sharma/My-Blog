<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Calculating Term Frequency(tf) and Inverse Document Frequency(idf) in Information Retrieval | In depth Blogs</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Calculating Term Frequency(tf) and Inverse Document Frequency(idf) in Information Retrieval" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="An easy to use blogging platform with support for Jupyter Notebooks." />
<meta property="og:description" content="An easy to use blogging platform with support for Jupyter Notebooks." />
<link rel="canonical" href="https://divay9sharma.github.io/My-Blog/2020/09/12/tf-idf.html" />
<meta property="og:url" content="https://divay9sharma.github.io/My-Blog/2020/09/12/tf-idf.html" />
<meta property="og:site_name" content="In depth Blogs" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-09-12T00:00:00-05:00" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://divay9sharma.github.io/My-Blog/2020/09/12/tf-idf.html"},"description":"An easy to use blogging platform with support for Jupyter Notebooks.","@type":"BlogPosting","url":"https://divay9sharma.github.io/My-Blog/2020/09/12/tf-idf.html","headline":"Calculating Term Frequency(tf) and Inverse Document Frequency(idf) in Information Retrieval","dateModified":"2020-09-12T00:00:00-05:00","datePublished":"2020-09-12T00:00:00-05:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/My-Blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://divay9sharma.github.io/My-Blog/feed.xml" title="In depth Blogs" /><link rel="shortcut icon" type="image/x-icon" href="/My-Blog/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Calculating Term Frequency(tf) and Inverse Document Frequency(idf) in Information Retrieval | In depth Blogs</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Calculating Term Frequency(tf) and Inverse Document Frequency(idf) in Information Retrieval" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="An easy to use blogging platform with support for Jupyter Notebooks." />
<meta property="og:description" content="An easy to use blogging platform with support for Jupyter Notebooks." />
<link rel="canonical" href="https://divay9sharma.github.io/My-Blog/2020/09/12/tf-idf.html" />
<meta property="og:url" content="https://divay9sharma.github.io/My-Blog/2020/09/12/tf-idf.html" />
<meta property="og:site_name" content="In depth Blogs" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-09-12T00:00:00-05:00" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://divay9sharma.github.io/My-Blog/2020/09/12/tf-idf.html"},"description":"An easy to use blogging platform with support for Jupyter Notebooks.","@type":"BlogPosting","url":"https://divay9sharma.github.io/My-Blog/2020/09/12/tf-idf.html","headline":"Calculating Term Frequency(tf) and Inverse Document Frequency(idf) in Information Retrieval","dateModified":"2020-09-12T00:00:00-05:00","datePublished":"2020-09-12T00:00:00-05:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://divay9sharma.github.io/My-Blog/feed.xml" title="In depth Blogs" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/My-Blog/">In depth Blogs</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/My-Blog/about/">About Me</a><a class="page-link" href="/My-Blog/search/">Search</a><a class="page-link" href="/My-Blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Calculating Term Frequency(tf) and Inverse Document Frequency(idf) in Information Retrieval</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-09-12T00:00:00-05:00" itemprop="datePublished">
        Sep 12, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      5 min read
    
</span></p>

    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/Divay9Sharma/My-Blog/tree/master/_notebooks/2020-09-12-tf-idf.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/My-Blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/Divay9Sharma/My-Blog/master?filepath=_notebooks%2F2020-09-12-tf-idf.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/My-Blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/Divay9Sharma/My-Blog/blob/master/_notebooks/2020-09-12-tf-idf.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/My-Blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-09-12-tf-idf.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;stopwords&#39;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">RegexpTokenizer</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.stop_words</span> <span class="kn">import</span> <span class="n">ENGLISH_STOP_WORDS</span>
<span class="n">stopWords</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">ENGLISH_STOP_WORDS</span><span class="p">)</span> <span class="o">+</span> <span class="n">nltk</span><span class="o">.</span><span class="n">corpus</span><span class="o">.</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;english&#39;</span><span class="p">))</span>
<span class="n">regex</span> <span class="o">=</span> <span class="n">RegexpTokenizer</span><span class="p">(</span><span class="s1">&#39;\w+&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>[nltk_data] Downloading package stopwords to C:\Users\Divay
[nltk_data]     Sharma\AppData\Roaming\nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
c:\users\divay sharma\appdata\local\programs\python\python37-32\lib\site-packages\sklearn\utils\deprecation.py:144: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.
  warnings.warn(message, FutureWarning)
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;assi3_data.txt&quot;</span><span class="p">,</span><span class="s2">&quot;r&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
<span class="n">file</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#34;1.Boolean model (Doc1) &#39;&#39;&#39;The (standard) Boolean model of information retrieval (BIR)[1] is a classical information retrieval (IR) model and, at the same time, the first and most-adopted one. It is used by many IR systems to this day.[citation needed] The BIR is based on Boolean logic and classical set theory in that both the documents to be searched and the user&#39;s query are conceived as sets of terms. Retrieval is based on whether or not the documents contain the query terms. &#39;&#39;&#39;\n&#34;,
 &#34;2.probabilistic relevance model(doc2) &#39;&#39;&#39;The probabilistic relevance model[1][2] was devised by Stephen E. Robertson and Karen SpÃ¤rck Jones as a framework for probabilistic models to come. It is a formalism of information retrieval useful to derive ranking functions used by search engines and web search engines in order to rank matching documents according to their relevance to a given search query.It is a theoretical model estimating the probability that a document dj is relevant to a query q. The model assumes that this probability of relevance depends on the query and document representations. Furthermore, it assumes that there is a portion of all documents that is preferred by the user as the answer set for query q. Such an ideal answer set is called R and should maximize the overall probability of relevance to that user. The prediction is that documents in this set R are relevant to the query, while documents not present in the set are non-relevant. &#39;&#39;&#39;\n&#34;,
 &#34;3.Vector space model(doc3) &#39;&#39;&#39;Vector space model or term vector model is an algebraic model for representing text documents (and any objects, in general) as vectors of identifiers (such as index terms). It is used in information filtering, information retrieval, indexing and relevancy rankings. Its first use was in the SMART Information Retrieval System. Each dimension corresponds to a separate term. If a term occurs in the document, its value in the vector is non-zero. Several different ways of computing these values, also known as (term) weights, have been developed. One of the best known schemes is tf-idf weighting (see the example below).The definition of term depends on the application. Typically terms are single words, keywords, or longer phrases. If words are chosen to be the terms, the dimensionality of the vector is the number of words in the vocabulary (the number of distinct words occurring in the corpus).Vector operations can be used to compare documents with queries. &#39;&#39;&#39;&#34;]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The tf-idf weight is a weight often used in information retrieval and text mining. This weight is a statistical measure used to evaluate how important a word is to a document in a collection or corpus. The importance increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus (data-set).</p>
<h4 id="Term-Frequency">Term Frequency<a class="anchor-link" href="#Term-Frequency"> </a></h4><p>This measures the frequency of a word in a document. This highly depends on the length of the document and the generality of word. TF is individual to each document and word, hence we can formulate TF as follows.</p>
<h4 id="Document-Frequency">Document Frequency<a class="anchor-link" href="#Document-Frequency"> </a></h4><p>This measures the importance of document in whole set of corpus, this is very similar to TF. The only difference is that TF is frequency counter for a term t in document d, where as DF is the count of occurrences of term t in the document set N.</p>
<h4 id="Inverse-Document-Frequency">Inverse Document Frequency<a class="anchor-link" href="#Inverse-Document-Frequency"> </a></h4><p>IDF is the inverse of the document frequency which measures the informativeness of term t.</p>
\begin{align}
tf-idf(t, d) = tf(t, d) * log(N/(df + 1))
\end{align}
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">calculate_tf_idf</span><span class="p">(</span><span class="n">file</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
    <span class="n">tf</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">word_count</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">idf</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">file</span><span class="p">:</span>
        <span class="n">words</span> <span class="o">=</span> <span class="n">regex</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
        <span class="n">doc_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
            <span class="n">word</span> <span class="o">=</span> <span class="n">word</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopWords</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">idf</span><span class="p">:</span>
                    <span class="n">idf</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">count</span> <span class="o">=</span> <span class="n">count</span> <span class="o">+</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">doc_dict</span><span class="p">:</span>
                    <span class="n">doc_dict</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">doc_dict</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">doc_dict</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">doc_dict</span><span class="p">)</span>
        <span class="n">word_count</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">count</span><span class="p">)</span>
        
    <span class="c1">#Calculate tf</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tf</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="n">tf</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">word</span><span class="p">]</span><span class="o">/</span><span class="n">word_count</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    
    <span class="c1">#Calculate tdf</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">idf</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tf</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                <span class="n">idf</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">idf</span><span class="p">[</span><span class="n">word</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span>
        <span class="n">idf</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="p">(</span><span class="n">idf</span><span class="p">[</span><span class="n">word</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1">#Calculate tf-idf</span>
    <span class="n">tf_idf</span> <span class="o">=</span> <span class="n">tf</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tf_idf</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="n">tf_idf</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">word</span><span class="p">]</span><span class="o">*</span><span class="n">idf</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">tf_idf</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tf_idf</span> <span class="o">=</span> <span class="n">calculate_tf_idf</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>tf-idf value for 1st document</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tf_idf</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;1&#39;: 0.03150669002545206,
 &#39;boolean&#39;: 0.06247436808232875,
 &#39;model&#39;: 0.03815562190468791,
 &#39;doc1&#39;: 0.020824789360776252,
 &#39;standard&#39;: 0.020824789360776252,
 &#39;information&#39;: 0.02543708126979194,
 &#39;retrieval&#39;: 0.03815562190468791,
 &#39;bir&#39;: 0.041649578721552505,
 &#39;classical&#39;: 0.041649578721552505,
 &#39;ir&#39;: 0.041649578721552505,
 &#39;time&#39;: 0.020824789360776252,
 &#39;adopted&#39;: 0.020824789360776252,
 &#39;used&#39;: 0.01271854063489597,
 &#39;systems&#39;: 0.020824789360776252,
 &#39;day&#39;: 0.020824789360776252,
 &#39;citation&#39;: 0.020824789360776252,
 &#39;needed&#39;: 0.020824789360776252,
 &#39;based&#39;: 0.041649578721552505,
 &#39;logic&#39;: 0.020824789360776252,
 &#39;set&#39;: 0.01575334501272603,
 &#39;theory&#39;: 0.020824789360776252,
 &#39;documents&#39;: 0.02543708126979194,
 &#39;searched&#39;: 0.020824789360776252,
 &#39;user&#39;: 0.01575334501272603,
 &#39;query&#39;: 0.03150669002545206,
 &#39;conceived&#39;: 0.020824789360776252,
 &#39;sets&#39;: 0.020824789360776252,
 &#39;terms&#39;: 0.03150669002545206,
 &#39;contain&#39;: 0.020824789360776252}</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">chcek_query</span><span class="p">(</span><span class="n">tf_idf</span><span class="p">,</span><span class="n">query</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tf_idf</span><span class="p">)</span>
    <span class="n">vocab</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">query</span> <span class="o">=</span> <span class="n">regex</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">query</span><span class="p">:</span>
        <span class="n">word</span> <span class="o">=</span> <span class="n">word</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopWords</span><span class="p">:</span>
            <span class="n">vocab</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
    <span class="n">doc_score</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">score</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">vocab</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tf_idf</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                <span class="n">score</span> <span class="o">=</span> <span class="n">score</span> <span class="o">+</span> <span class="n">tf_idf</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">word</span><span class="p">]</span>
        <span class="n">doc_score</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">doc_score</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">doc_score</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">doc_score</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Testing with queries</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;Vector space model&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Doc &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">chcek_query</span><span class="p">(</span><span class="n">tf_idf</span><span class="p">,</span><span class="n">query</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[0.03815562190468791, 0.024331121214583595, 0.10631987785261035]
Doc 2
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;Stephen E. Robertson&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Doc &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">chcek_query</span><span class="p">(</span><span class="n">tf_idf</span><span class="p">,</span><span class="n">query</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[0, 0.029879045604592015, 0]
Doc 1
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;classical information retrieval&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Doc &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">chcek_query</span><span class="p">(</span><span class="n">tf_idf</span><span class="p">,</span><span class="n">query</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[0.10524228189603235, 0.012165560607291797, 0.03108976599641237]
Doc 0
</pre>
</div>
</div>

</div>
</div>

</div>
    

</div>



  </div><a class="u-url" href="/My-Blog/2020/09/12/tf-idf.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/My-Blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/My-Blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/My-Blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" title="fastai"><svg class="svg-icon grey"><use xlink:href="/My-Blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/My-Blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
